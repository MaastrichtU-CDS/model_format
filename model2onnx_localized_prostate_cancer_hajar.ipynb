{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skl2onnx import to_onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example intercepts and coefficients for Logistic Regression\n",
    "intercept_1_year = -0.5  # Example value for year 1\n",
    "coefficients_1_year = np.array([0.1, -0.2, 0.3, 0.4, -0.1, 0.5, -0.3, 0.2, -0.4, 0.6])  # Example values\n",
    "\n",
    "intercept_2_year = -0.3  # Example value for year 2\n",
    "coefficients_2_year = np.array([-0.1, 0.2, -0.3, 0.4, -0.5, 0.6, -0.2, 0.1, 0.3, -0.4])  # Example values\n",
    "\n",
    "# Feature names based on the document\n",
    "feature_names = [\"BMI\", \"WeightLoss\", \"TF\", \"PS\", \"Tumorlocation\", \"Tclassification\", \n",
    "                 \"Nclassification\", \"Systherapy\", \"RTdose_subman\", \"RTdosesalivary\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year 1 Logistic Regression\n",
    "lr_1_year = LogisticRegression()\n",
    "lr_1_year.intercept_ = np.array([intercept_1_year])\n",
    "lr_1_year.coef_ = np.array([coefficients_1_year])\n",
    "lr_1_year.feature_names_in_ = feature_names\n",
    "lr_1_year.classes_ = np.array([0, 1])  # Binary classification\n",
    "\n",
    "# Year 2 Logistic Regression\n",
    "lr_2_year = LogisticRegression()\n",
    "lr_2_year.intercept_ = np.array([intercept_2_year])\n",
    "lr_2_year.coef_ = np.array([coefficients_2_year])\n",
    "lr_2_year.feature_names_in_ = feature_names\n",
    "lr_2_year.classes_ = np.array([0, 1])  # Binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year 1 Random Forest\n",
    "rf_1_year = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)  # Configure as per your study details\n",
    "rf_1_year.feature_names_in_ = feature_names\n",
    "rf_1_year.classes_ = np.array([0, 1])  # Binary classification\n",
    "\n",
    "# Year 2 Random Forest\n",
    "rf_2_year = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)  # Configure as per your study details\n",
    "rf_2_year.feature_names_in_ = feature_names\n",
    "rf_2_year.classes_ = np.array([0, 1])  # Binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Year 1 Support Vector Machine\n",
    "svm_1_year = SVC(probability=True, kernel='linear')  # Configure as per your study details\n",
    "svm_1_year.feature_names_in_ = feature_names\n",
    "svm_1_year.classes_ = np.array([0, 1])  # Binary classification\n",
    "\n",
    "# Year 2 Support Vector Machine\n",
    "svm_2_year = SVC(probability=True, kernel='linear')  # Configure as per your study details\n",
    "svm_2_year.feature_names_in_ = feature_names\n",
    "svm_2_year.classes_ = np.array([0, 1])  # Binary classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to infer initial types for ONNX conversion\n",
    "def infer_initial_types():\n",
    "    return [('input', FloatTensorType([None, 10]))]  # Assuming 10 features\n",
    "\n",
    "# Assign infer initial types to each model\n",
    "lr_1_year.infer_initial_types = infer_initial_types\n",
    "lr_2_year.infer_initial_types = infer_initial_types\n",
    "rf_1_year.infer_initial_types = infer_initial_types\n",
    "rf_2_year.infer_initial_types = infer_initial_types\n",
    "svm_1_year.infer_initial_types = infer_initial_types\n",
    "svm_2_year.infer_initial_types = infer_initial_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Model should have attribute 'n_outputs_' or 'n_trees_per_iteration_'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m lr_1_year_onnx \u001b[38;5;241m=\u001b[39m to_onnx(lr_1_year, initial_types\u001b[38;5;241m=\u001b[39mlr_1_year\u001b[38;5;241m.\u001b[39minfer_initial_types())\n\u001b[1;32m      3\u001b[0m lr_2_year_onnx \u001b[38;5;241m=\u001b[39m to_onnx(lr_2_year, initial_types\u001b[38;5;241m=\u001b[39mlr_2_year\u001b[38;5;241m.\u001b[39minfer_initial_types())\n\u001b[0;32m----> 4\u001b[0m rf_1_year_onnx \u001b[38;5;241m=\u001b[39m to_onnx(rf_1_year, initial_types\u001b[38;5;241m=\u001b[39mrf_1_year\u001b[38;5;241m.\u001b[39minfer_initial_types())\n\u001b[1;32m      5\u001b[0m rf_2_year_onnx \u001b[38;5;241m=\u001b[39m to_onnx(rf_2_year, initial_types\u001b[38;5;241m=\u001b[39mrf_2_year\u001b[38;5;241m.\u001b[39minfer_initial_types())\n\u001b[1;32m      6\u001b[0m svm_1_year_onnx \u001b[38;5;241m=\u001b[39m to_onnx(svm_1_year, initial_types\u001b[38;5;241m=\u001b[39msvm_1_year\u001b[38;5;241m.\u001b[39minfer_initial_types())\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/skl2onnx/convert.py:304\u001b[0m, in \u001b[0;36mto_onnx\u001b[0;34m(model, X, name, initial_types, target_opset, options, white_op, black_op, final_types, dtype, naming, model_optim, verbose)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[to_onnx] initial_types=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m initial_types)\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m convert_sklearn(\n\u001b[1;32m    305\u001b[0m     model,\n\u001b[1;32m    306\u001b[0m     initial_types\u001b[38;5;241m=\u001b[39minitial_types,\n\u001b[1;32m    307\u001b[0m     target_opset\u001b[38;5;241m=\u001b[39mtarget_opset,\n\u001b[1;32m    308\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    309\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    310\u001b[0m     white_op\u001b[38;5;241m=\u001b[39mwhite_op,\n\u001b[1;32m    311\u001b[0m     black_op\u001b[38;5;241m=\u001b[39mblack_op,\n\u001b[1;32m    312\u001b[0m     final_types\u001b[38;5;241m=\u001b[39mfinal_types,\n\u001b[1;32m    313\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    314\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    315\u001b[0m     naming\u001b[38;5;241m=\u001b[39mnaming,\n\u001b[1;32m    316\u001b[0m     model_optim\u001b[38;5;241m=\u001b[39mmodel_optim,\n\u001b[1;32m    317\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/skl2onnx/convert.py:206\u001b[0m, in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, model_optim, verbose)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[convert_sklearn] convert_topology\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m onnx_model \u001b[38;5;241m=\u001b[39m convert_topology(\n\u001b[1;32m    207\u001b[0m     topology,\n\u001b[1;32m    208\u001b[0m     name,\n\u001b[1;32m    209\u001b[0m     doc_string,\n\u001b[1;32m    210\u001b[0m     target_opset,\n\u001b[1;32m    211\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m    212\u001b[0m     remove_identity\u001b[38;5;241m=\u001b[39mmodel_optim \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m intermediate,\n\u001b[1;32m    213\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    214\u001b[0m )\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[convert_sklearn] end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/skl2onnx/common/_topology.py:1533\u001b[0m, in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, options, remove_identity, verbose)\u001b[0m\n\u001b[1;32m   1522\u001b[0m container \u001b[38;5;241m=\u001b[39m ModelComponentContainer(\n\u001b[1;32m   1523\u001b[0m     target_opset,\n\u001b[1;32m   1524\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1528\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m   1529\u001b[0m )\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;66;03m# Traverse the graph from roots to leaves\u001b[39;00m\n\u001b[1;32m   1532\u001b[0m \u001b[38;5;66;03m# This loop could eventually be parallelized.\u001b[39;00m\n\u001b[0;32m-> 1533\u001b[0m topology\u001b[38;5;241m.\u001b[39mconvert_operators(container\u001b[38;5;241m=\u001b[39mcontainer, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m   1534\u001b[0m container\u001b[38;5;241m.\u001b[39mensure_topological_order()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(container\u001b[38;5;241m.\u001b[39minputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/skl2onnx/common/_topology.py:1351\u001b[0m, in \u001b[0;36mTopology.convert_operators\u001b[0;34m(self, container, verbose)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     _check_variable_out_(variable, operator)\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_shape_calculator(operator)\n\u001b[0;32m-> 1351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_converter(operator, container, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;66;03m# If an operator contains a sequence of operators,\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[38;5;66;03m# output variables are not necessarily known at this stage.\u001b[39;00m\n\u001b[1;32m   1355\u001b[0m operator\u001b[38;5;241m.\u001b[39minit_status(is_evaluated\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/skl2onnx/common/_topology.py:1134\u001b[0m, in \u001b[0;36mTopology.call_converter\u001b[0;34m(self, operator, container, verbose)\u001b[0m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[call_converter] call converter for \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m operator\u001b[38;5;241m.\u001b[39mtype)\n\u001b[1;32m   1128\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Conv] call \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m fed \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1130\u001b[0m     operator,\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mis_fed) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m operator\u001b[38;5;241m.\u001b[39minputs),\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mis_fed) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m operator\u001b[38;5;241m.\u001b[39moutputs),\n\u001b[1;32m   1133\u001b[0m )\n\u001b[0;32m-> 1134\u001b[0m conv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscopes[\u001b[38;5;241m0\u001b[39m], operator, container)\n\u001b[1;32m   1135\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Conv] end - \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, operator)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/skl2onnx/common/_registration.py:27\u001b[0m, in \u001b[0;36mRegisteredConverter.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mraw_operator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m         args[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39m_get_allowed_options(args[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mraw_operator)\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fct(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/skl2onnx/operator_converters/random_forest.py:129\u001b[0m, in \u001b[0;36mconvert_sklearn_random_forest_classifier\u001b[0;34m(scope, operator, container, op_type, op_domain, op_version)\u001b[0m\n\u001b[1;32m    127\u001b[0m     options \u001b[38;5;241m=\u001b[39m container\u001b[38;5;241m.\u001b[39mget_options(op, \u001b[38;5;28mdict\u001b[39m(raw_scores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel should have attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_outputs_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_trees_per_iteration_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    133\u001b[0m use_raw_scores \u001b[38;5;241m=\u001b[39m options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_outputs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(op, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(op, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Model should have attribute 'n_outputs_' or 'n_trees_per_iteration_'."
     ]
    }
   ],
   "source": [
    "# Convert each model to ONNX format\n",
    "lr_1_year_onnx = to_onnx(lr_1_year, initial_types=lr_1_year.infer_initial_types())\n",
    "lr_2_year_onnx = to_onnx(lr_2_year, initial_types=lr_2_year.infer_initial_types())\n",
    "rf_1_year_onnx = to_onnx(rf_1_year, initial_types=rf_1_year.infer_initial_types())\n",
    "rf_2_year_onnx = to_onnx(rf_2_year, initial_types=rf_2_year.infer_initial_types())\n",
    "svm_1_year_onnx = to_onnx(svm_1_year, initial_types=svm_1_year.infer_initial_types())\n",
    "svm_2_year_onnx = to_onnx(svm_2_year, initial_types=svm_2_year.infer_initial_types())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ONNX models to files\n",
    "with open(\"lr_1_year.onnx\", \"wb\") as f:\n",
    "    f.write(lr_1_year_onnx.SerializeToString())\n",
    "\n",
    "with open(\"lr_2_year.onnx\", \"wb\") as f:\n",
    "    f.write(lr_2_year_onnx.SerializeToString())\n",
    "\n",
    "with open(\"rf_1_year.onnx\", \"wb\") as f:\n",
    "    f.write(rf_1_year_onnx.SerializeToString())\n",
    "\n",
    "with open(\"rf_2_year.onnx\", \"wb\") as f:\n",
    "    f.write(rf_2_year_onnx.SerializeToString())\n",
    "\n",
    "with open(\"svm_1_year.onnx\", \"wb\") as f:\n",
    "    f.write(svm_1_year_onnx.SerializeToString())\n",
    "\n",
    "with open(\"svm_2_year.onnx\", \"wb\") as f:\n",
    "    f.write(svm_2_year_onnx.SerializeToString())\n",
    "\n",
    "print(\"Models successfully converted and saved in ONNX format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
